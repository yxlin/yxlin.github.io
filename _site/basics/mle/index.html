<!DOCTYPE html>

<html>
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1">

		<!-- Begin Jekyll SEO tag v2.4.0 -->
<title>Maximising Likelihoods | Cognitive Models</title>
<meta name="generator" content="Jekyll v3.7.2" />
<meta property="og:title" content="Maximising Likelihoods" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="This is a short note for one method to conduct maximum likelihood estimation (MLE) to fit the LBA model." />
<meta property="og:description" content="This is a short note for one method to conduct maximum likelihood estimation (MLE) to fit the LBA model." />
<link rel="canonical" href="http://localhost:4000/basics/mle/" />
<meta property="og:url" content="http://localhost:4000/basics/mle/" />
<meta property="og:site_name" content="Cognitive Models" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-10-03T06:11:35+00:00" />
<script type="application/ld+json">
{"datePublished":"2020-10-03T06:11:35+00:00","description":"This is a short note for one method to conduct maximum likelihood estimation (MLE) to fit the LBA model.","@type":"Article","url":"http://localhost:4000/basics/mle/","publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"http://localhost:4000/siteicon.png"}},"headline":"Maximising Likelihoods","dateModified":"2020-10-03T06:11:35+00:00","@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->

		<link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="Cognitive Models" />

		<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Merriweather:400,400italic,700,700italic|Open+Sans:400,400italic,600,600italic,700,700italic|Inconsolata:400,700">
		<link rel="stylesheet" href="/css/main.css">
		<link rel="apple-touch-icon" href="/apple-touch-icon.png">
		<link rel="icon" type="image/png" href="/touch-icon.png" sizes="192x192">
		<link rel="icon" type="image/png" href="/images/favicon.png">

		
	</head>

	<body>
	  <header>
	    <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML"></script>
	    
			<h1>
				<a href="/"><img src="/images/emblem.svg" width="40" height="40" alt="Cognitive Models logo"></a>
				Cognitive Models
				<button type="button" class="open-nav" id="open-nav"></button>
			</h1>

			<form action="/search/" method="get">
				<input type="text" name="q" id="search-input" placeholder="Search" autofocus>
				<input type="submit" value="Search" style="display: none;">
			</form>

			<nav >
				<ul>
					<li class="nav-item top-level ">
						
						<a href="/"></a>
					</li>
				</ul>

				<ul>
					
					
						<li class="nav-item top-level ">
							
							<a href="/BUGS/hnormal/">BUGS Examples Volumn 1</a>
							<ul>
								
									<li class="nav-item "><a href="/BUGS/hnormal/">Hierarchical Normal Model</a></li>
								
									<li class="nav-item "><a href="/BUGS/seeds/">Random effect logistic regression</a></li>
								
							</ul>
						</li>
					
						<li class="nav-item top-level ">
							
							<a href="/approximation/kde/">Likelihood Free Method</a>
							<ul>
								
									<li class="nav-item "><a href="/approximation/kde/">Kernel Density Estimation</a></li>
								
									<li class="nav-item "><a href="/approximation/pda/">Probability Density Approximation</a></li>
								
									<li class="nav-item "><a href="/approximation/ppda/">Parallel Probability Density Approximation</a></li>
								
							</ul>
						</li>
					
						<li class="nav-item top-level current">
							
							<a href="/basics/model_array/">Modelling Basics</a>
							<ul>
								
									<li class="nav-item "><a href="/basics/model_array/">Model Array</a></li>
								
									<li class="nav-item "><a href="/basics/simulation/">Simulation</a></li>
								
									<li class="nav-item "><a href="/basics/descriptive/">Descriptive Statistics</a></li>
								
									<li class="nav-item "><a href="/basics/summary/">Summary Statistics</a></li>
								
									<li class="nav-item "><a href="/basics/leastsq/">Least Square Method</a></li>
								
									<li class="nav-item current"><a href="/basics/mle/">Maximising Likelihoods</a></li>
								
							</ul>
						</li>
					
						<li class="nav-item top-level ">
							
							<a href="/bayes-basics/theorem/">Bayesian Basics</a>
							<ul>
								
									<li class="nav-item "><a href="/bayes-basics/theorem/">Bayes' Theorem</a></li>
								
									<li class="nav-item "><a href="/bayes-basics/prior/">Prior Distribution</a></li>
								
									<li class="nav-item "><a href="/bayes-basics/likelihood/">Model Likelihood</a></li>
								
									<li class="nav-item "><a href="/bayes-basics/posterior/">Posterior Distribution</a></li>
								
									<li class="nav-item "><a href="/bayes-basics/diagnosis/">Checking Fitted Models</a></li>
								
							</ul>
						</li>
					
						<li class="nav-item top-level ">
							
							<a href="/cognitive-model/lba/">Cognitive Model</a>
							<ul>
								
									<li class="nav-item "><a href="/cognitive-model/lba/">LBA Model</a></li>
								
									<li class="nav-item "><a href="/cognitive-model/pm/">PM Model</a></li>
								
									<li class="nav-item "><a href="/cognitive-model/plba/">PLBA Model</a></li>
								
									<li class="nav-item "><a href="/cognitive-model/ddm/">Diffusion Decision Model</a></li>
								
									<li class="nav-item "><a href="/cognitive-model/ddm1c/">One-choice Diffusion Decision Model</a></li>
								
									<li class="nav-item "><a href="/cognitive-model/cddm/">Circular Drift-diffusion Model</a></li>
								
									<li class="nav-item "><a href="/cognitive-model/pddm/">PDDM</a></li>
								
									<li class="nav-item "><a href="/cognitive-model/lba3/">Three-accumulator LBA Model</a></li>
								
									<li class="nav-item "><a href="/cognitive-model/lca/">LCA Model</a></li>
								
							</ul>
						</li>
					
						<li class="nav-item top-level ">
							
							<a href="/fixed-effect-model/one_participant/">Fixed-effects Model</a>
							<ul>
								
									<li class="nav-item "><a href="/fixed-effect-model/one_participant/">One Participant</a></li>
								
									<li class="nav-item "><a href="/fixed-effect-model/many_participants/">Multiple Participants</a></li>
								
									<li class="nav-item "><a href="/fixed-effect-model/cddm12S/">CDDM</a></li>
								
							</ul>
						</li>
					
						<li class="nav-item top-level ">
							
							<a href="/mcmc/mcmc/">Modern Bayesian Statistics</a>
							<ul>
								
									<li class="nav-item "><a href="/mcmc/mcmc/">Markov Chain Monte Carlo</a></li>
								
									<li class="nav-item "><a href="/mcmc/rwm/">Random Walk Metropolis</a></li>
								
									<li class="nav-item "><a href="/mcmc/hastings/">Metropolis-Hastings</a></li>
								
							</ul>
						</li>
					
						<li class="nav-item top-level ">
							
							<a href="/random-effect-model/hlba/">Hierarchical Model</a>
							<ul>
								
									<li class="nav-item "><a href="/random-effect-model/hlba/">HLBA Model</a></li>
								
									<li class="nav-item "><a href="/random-effect-model/hddm/">HDDM</a></li>
								
									<li class="nav-item "><a href="/random-effect-model/shooting-decision1/">Shooting Decision Model - Recovery Study</a></li>
								
									<li class="nav-item "><a href="/random-effect-model/shooting-decision2/">Shooting Decision Model - Empirical Data</a></li>
								
									<li class="nav-item "><a href="/random-effect-model/hcddm/">HCDDM</a></li>
								
									<li class="nav-item "><a href="/random-effect-model/hpm/">HPM Model</a></li>
								
							</ul>
						</li>
					
						<li class="nav-item top-level ">
							
							<a href="/sampling/genetic/">Sampling Techniques</a>
							<ul>
								
									<li class="nav-item "><a href="/sampling/genetic/">Population-based Monte Carlo</a></li>
								
									<li class="nav-item "><a href="/sampling/crossover/">Crossover</a></li>
								
									<li class="nav-item "><a href="/sampling/migration/">Migration</a></li>
								
									<li class="nav-item "><a href="/sampling/mutation/">Mutation</a></li>
								
									<li class="nav-item "><a href="/sampling/demc/">Differential Evolution Monte Carlo</a></li>
								
									<li class="nav-item "><a href="/sampling/demcmc/">Differential Evolution Markov Chain Monte Carlo</a></li>
								
									<li class="nav-item "><a href="/sampling/dgmc/">Distributed Genetic Monte Carlo</a></li>
								
							</ul>
						</li>
					
				</ul>

				<ul>
					<li class="nav-item top-level ">
						
						<a href="/changelog/">Change Log</a>
					</li>
				</ul>
			</nav>
		</header>

		<section class="main">
			<div class="page-header">
				<h2>Modelling Basics</h2>
				<h3>Maximising Likelihoods</h3>
			</div>
			<article class="content">
				<p>This is a short note for one method to conduct
maximum likelihood estimation (MLE) to fit the LBA model.</p>

<p>In essence, the MLE is not a very difficult statistical technique,
but there are some trivialities regarding to the cognitive model
and its influence on the usage of optimiser that must be addressed.
Otherwise, you would not recover the parameters in the LBA model (or
cognitive models in general).</p>

<p>In short, you must adjust either the objective function, the method of
data preparation, or the method of proposing parameters according to a
specific cognitive model. For example, the non-decision time must not go
below 0 second. If you do not (or cannot) add this constraint on
the optimiser (e.g., the R function, <em>optim</em>), the resulting
fit may not converge or the estimates (even converged)
will be unreasonable, psychologically speaking.</p>

<p>Below I use <em>ggdmc</em> to conduct a simulation study to demonstrate the point.</p>

<h2 id="simulation-study">Simulation study</h2>

<p>Firstly, I use the BuildModel function to set up a null model
with only a stimulus factor (denoted <em>S</em>).  That is, the model parameters
do not associate with any factors.</p>

<p>Next I arbitrarily set up a true parameter vector, <em>p.vector</em> and request 100
trials per condition. My aim is to recover the true parameters.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">require</span><span class="p">(</span><span class="n">ggdmc</span><span class="p">)</span>
<span class="k">model</span> <span class="p">&lt;-</span> <span class="n">BuildModel</span><span class="p">(</span>
  <span class="n">p</span><span class="p">.</span><span class="n">map</span>     <span class="p">=</span> <span class="k">list</span><span class="p">(</span><span class="n">A</span> <span class="p">=</span> <span class="s2">"1"</span><span class="p">,</span> <span class="n">B</span> <span class="p">=</span> <span class="s2">"1"</span><span class="p">,</span> <span class="n">t0</span> <span class="p">=</span> <span class="s2">"1"</span><span class="p">,</span> <span class="n">mean_v</span> <span class="p">=</span> <span class="s2">"M"</span><span class="p">,</span> <span class="n">sd_v</span> <span class="p">=</span> <span class="s2">"1"</span><span class="p">,</span>
                   <span class="n">st0</span> <span class="p">=</span> <span class="s2">"1"</span><span class="p">),</span>
  <span class="n">match</span><span class="p">.</span><span class="n">map</span> <span class="p">=</span> <span class="k">list</span><span class="p">(</span><span class="n">M</span> <span class="p">=</span> <span class="k">list</span><span class="p">(</span><span class="n">s1</span> <span class="p">=</span> <span class="m">1</span><span class="p">,</span> <span class="n">s2</span> <span class="p">=</span> <span class="m">2</span><span class="p">)),</span>
  <span class="n">factors</span>   <span class="p">=</span> <span class="k">list</span><span class="p">(</span><span class="n">S</span> <span class="p">=</span> <span class="n">c</span><span class="p">(</span><span class="s2">"s1"</span><span class="p">,</span> <span class="s2">"s2"</span><span class="p">)),</span>
  <span class="n">constants</span> <span class="p">=</span> <span class="n">c</span><span class="p">(</span><span class="n">st0</span> <span class="p">=</span> <span class="m">0</span><span class="p">,</span> <span class="n">sd_v</span> <span class="p">=</span> <span class="m">1</span><span class="p">),</span>
  <span class="n">responses</span> <span class="p">=</span> <span class="n">c</span><span class="p">(</span><span class="s2">"r1"</span><span class="p">,</span> <span class="s2">"r2"</span><span class="p">),</span>
  <span class="n">type</span>      <span class="p">=</span> <span class="s2">"norm"</span><span class="p">)</span>

<span class="n">p</span><span class="p">.</span><span class="n">vector</span> <span class="p">&lt;-</span> <span class="n">c</span><span class="p">(</span><span class="n">A</span> <span class="p">=</span> <span class="m">.75</span><span class="p">,</span> <span class="n">B</span> <span class="p">=</span> <span class="m">1.25</span><span class="p">,</span> <span class="n">t0</span> <span class="p">=</span> <span class="m">.15</span><span class="p">,</span> <span class="n">mean_v</span><span class="p">.</span><span class="nb">true</span> <span class="p">=</span> <span class="m">2.5</span><span class="p">,</span> <span class="n">mean_v</span><span class="p">.</span><span class="nb">false</span> <span class="p">=</span> <span class="m">1.5</span><span class="p">)</span>
<span class="n">ntrial</span> <span class="p">&lt;-</span> <span class="m">1e2</span>

<span class="p">##</span> <span class="n">I</span> <span class="n">used</span> <span class="n">the</span> <span class="n">seed</span> <span class="n">option</span> <span class="k">to</span> <span class="n">make</span> <span class="n">sure</span> <span class="n">I</span> <span class="n">always</span> <span class="n">replicate</span> <span class="n">the</span> <span class="n">result</span><span class="p">.</span>
<span class="n">dat</span> <span class="p">&lt;-</span> <span class="n">simulate</span><span class="p">(</span><span class="k">model</span><span class="p">,</span> <span class="n">nsim</span> <span class="p">=</span> <span class="n">ntrial</span><span class="p">,</span> <span class="n">ps</span> <span class="p">=</span> <span class="n">p</span><span class="p">.</span><span class="n">vector</span><span class="p">,</span> <span class="n">seed</span> <span class="p">=</span> <span class="m">123</span><span class="p">)</span>
<span class="n">dmi</span> <span class="p">&lt;-</span> <span class="n">BuildDMI</span><span class="p">(</span><span class="n">dat</span><span class="p">,</span> <span class="k">model</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="description-statistics">Description statistics</h2>
<p>As a good practice, we check some basic descriptive statistics. Here is the response
time distributions, drawn as one correct RT and one error RT histograms.</p>

<p><img src="/images/basics/mle_data.png" alt="mle_data" /></p>

<p>Note there are two histograms (i.e., distributions). This is one of
the specific feature in the choice RT models. This is sometimes dubbed 
defective distributions, meaning multiple distributions jointly composing a
complete model (integrated to 1).</p>

<p>The <em>likelihood</em> function in the <em>ggdmc</em> has considered this,
so you will not see how the internal C++ codes handle this triviality.
But if you use the bare-bones LBA density functions, say
“ggdmc:::n1PDFfixedt0” (meaning node 1 probability density
function), “ggdmc:::fptcdf” or “ggdmc:::fptpdf”, you need to handle
the calculation of “defective distributions” accordingly. These 
are the functions originally from Brown and Heathcote(2008), but since
version 0.2.6.7, <em>ggdmc</em> has no longer exposed them in R interface.</p>

<p>By the way, the top x axis in the above figure labels <em>TRUE</em>, representing
correct responses and <em>FALSE</em>, representing error responses. It is
not unusual to observe more correct responses than error responses, so
the simulation produces realistic data.</p>

<p>Since version 0.2.7.6, <em>ggdmc</em> uses S4 class to replace original 
informal S3 class. So the data is now stored as a slot in the dmi object.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## This is to create a column in the data frame to indicate
## correct and error responses.
dmi@data$C &lt;- ifelse(dmi@data$S == "s1" &amp; dmi@data$R == "r1", TRUE,
              ifelse(dmi@data$S == "s2" &amp; dmi@data$R == "r2", TRUE,
              ifelse(dmi@data$S == "s1" &amp; dmi@data$R == "r2" ,FALSE,
              ifelse(dmi@data$S == "s2" &amp; dmi@data$R == "r1", FALSE, NA))))
					 
prop.table(table(dmi@data$C))
## FALSE == error responses (25.5%)
## TRUE == correct responses (74.5%)
## FALSE  TRUE 
## 0.255 0.745

## The maximum (log) likelihoods
## 
den &lt;- likelihood(p.vector, dmi)
sum(log(den))
## [1] -112.7387

</code></pre></div></div>

<h2 id="maximum-likelihood-estimation">Maximum likelihood estimation</h2>

<p>The following is the objective function.  Note <em>data</em> must be
a data model instance. This requirement is to use <em>ggdmc</em>
internal to handle many trivialities, for instance, the defective
distributions, experimental design, transforming parameter
(<script type="math/tex">b = A + B</script>), etc.  If you use the bare-bones density functions,
you must handle these trivialities. Also I use negative log likelihood.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>objective_fun &lt;- function(par, data) {
  ## Internally, C++ likelihood function will read model type, and
  ## new Likelihood constructor (in Likelihood.hpp) will read S4 slot.
  ## So here data variable is OK to be a data-model instance
  den &lt;- likelihood(par, data)
  return(-sum(log(den)))
}
</code></pre></div></div>

<blockquote>
  <p>init_par[3] &lt;- runif(1, 0, min(dmi$RT))</p>
</blockquote>

<p>This line makes starting non-decision time not less than the minimal RT
in the data. This is another psychological consideration. It may help.
However, it does not guarantee the optimiser won’t propose a non-decision
time less than minimal RT in the data.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>init_par &lt;- runif(5)
init_par[3] &lt;- runif(1, 0, min(dmi@data$RT)) 
names(init_par) &lt;- c("A", "B", "t0", "mean_v.true", "mean_v.false")
res &lt;- nlminb(objective_fun, start = init_par, data = dmi, lower = 0)
round(res$par, 2)  ## remember to check res$convergence
</code></pre></div></div>

<p>Below is a list of possible estimates. The last line show
the true parameter vector for the convenience of comparison. The
first column shows the numbers of trial per condition.  At the
size of 1e5, the recovered values almost equal to the true values.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>##         A       B      t0 mean_v.true mean_v.false
## 1e2  0.79    0.98    0.17   2.26      0.77
## 1e2  0.86    1.74    0.04   2.80      1.82 
## 1e2  0.91    0.67    0.28   2.04      1.02 
## 1e2  0.72    1.36    0.14   2.74      1.60 
## 1e3  0.71    1.15    0.16   2.32      1.40 
## 1e3  0.61    1.63    0.08   2.70      1.76
## 1e4  0.71    1.28    0.15   2.51      1.50 
## 1e5  0.75    1.24    0.15   2.49      1.49 
## true 0.75    1.25    0.15   2.50      1.50

</code></pre></div></div>

<p>Instead of using the <em>optim</em> function, I opt to <em>nlminb</em>
function.  This is again a model specific consideration. In
the LBA model, A, B, and t0 must not be less than 0, so it
will help if we can impose this constraint. Both <em>optim</em> and <em>nlminb</em> offer
an argument, <em>lower</em>, to constraint the parameter proposals.
However, if you impose the <em>lower</em> constraint, <em>optim</em> allows
only (?) the optimisation method, “L-BFGS-B”, which does
not handle well infinite. Unfortunately, in fitting the
LBA model, it is likely some parameter proposals result in
infinite log-likelihoods.</p>

<h2 id="bonus">Bonus</h2>
<p>A better way to initialise a parameter proposal is to use prior
distributions. <em>rprior</em> in <em>ggdmc</em> allows you to easily do this. This is 
a step towards Bayesian.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>p.prior &lt;- BuildPrior(
  dists = c("tnorm", "tnorm", "beta", "tnorm", "tnorm"),
  p1    = c(A = 1, B = 1, t0 = 1, mean_v.true = 1, mean_v.false = 1),
  p2    = c(1,  1,  1, 1, 1),
  lower = c(rep(0, 3),  rep(NA, 2)),  
  upper = c(rep(NA, 2), 1, rep(NA, 2)))
  
init_par &lt;- rprior(p.prior)
##            A            B           t0  mean_v.true mean_v.false 
##         0.40         0.65         0.24         0.89        -0.26 

</code></pre></div></div>


			</article>
		</section>

		<script>
			document.getElementById("open-nav").addEventListener("click", function () {
				document.body.classList.toggle("nav-open");
			});

			
		</script>

		  
		</script>
	</body>
</html>
