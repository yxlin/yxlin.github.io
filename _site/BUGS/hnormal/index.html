<!DOCTYPE html>

<html>
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1">

		<!-- Begin Jekyll SEO tag v2.4.0 -->
<title>Hierarchical Normal Model | Cognitive Models</title>
<meta name="generator" content="Jekyll v3.7.2" />
<meta property="og:title" content="Hierarchical Normal Model" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Disclaimer: This tutorial uses an experimental (beta) version of ggdmc, which has added the functionality of fitting regression models. The software can be found in its GitHub." />
<meta property="og:description" content="Disclaimer: This tutorial uses an experimental (beta) version of ggdmc, which has added the functionality of fitting regression models. The software can be found in its GitHub." />
<link rel="canonical" href="http://localhost:4000/BUGS/hnormal/" />
<meta property="og:url" content="http://localhost:4000/BUGS/hnormal/" />
<meta property="og:site_name" content="Cognitive Models" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-10-03T06:11:35+00:00" />
<script type="application/ld+json">
{"datePublished":"2020-10-03T06:11:35+00:00","description":"Disclaimer: This tutorial uses an experimental (beta) version of ggdmc, which has added the functionality of fitting regression models. The software can be found in its GitHub.","@type":"Article","url":"http://localhost:4000/BUGS/hnormal/","publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"http://localhost:4000/siteicon.png"}},"headline":"Hierarchical Normal Model","dateModified":"2020-10-03T06:11:35+00:00","@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->

		<link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="Cognitive Models" />

		<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Merriweather:400,400italic,700,700italic|Open+Sans:400,400italic,600,600italic,700,700italic|Inconsolata:400,700">
		<link rel="stylesheet" href="/css/main.css">
		<link rel="apple-touch-icon" href="/apple-touch-icon.png">
		<link rel="icon" type="image/png" href="/touch-icon.png" sizes="192x192">
		<link rel="icon" type="image/png" href="/images/favicon.png">

		
	</head>

	<body>
	  <header>
	    <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML"></script>
	    
			<h1>
				<a href="/"><img src="/images/emblem.svg" width="40" height="40" alt="Cognitive Models logo"></a>
				Cognitive Models
				<button type="button" class="open-nav" id="open-nav"></button>
			</h1>

			<form action="/search/" method="get">
				<input type="text" name="q" id="search-input" placeholder="Search" autofocus>
				<input type="submit" value="Search" style="display: none;">
			</form>

			<nav >
				<ul>
					<li class="nav-item top-level ">
						
						<a href="/"></a>
					</li>
				</ul>

				<ul>
					
					
						<li class="nav-item top-level current">
							
							<a href="/BUGS/hnormal/">BUGS Examples Volumn 1</a>
							<ul>
								
									<li class="nav-item current"><a href="/BUGS/hnormal/">Hierarchical Normal Model</a></li>
								
									<li class="nav-item "><a href="/BUGS/seeds/">Random effect logistic regression</a></li>
								
							</ul>
						</li>
					
						<li class="nav-item top-level ">
							
							<a href="/approximation/kde/">Likelihood Free Method</a>
							<ul>
								
									<li class="nav-item "><a href="/approximation/kde/">Kernel Density Estimation</a></li>
								
									<li class="nav-item "><a href="/approximation/pda/">Probability Density Approximation</a></li>
								
									<li class="nav-item "><a href="/approximation/ppda/">Parallel Probability Density Approximation</a></li>
								
							</ul>
						</li>
					
						<li class="nav-item top-level ">
							
							<a href="/basics/model_array/">Modelling Basics</a>
							<ul>
								
									<li class="nav-item "><a href="/basics/model_array/">Model Array</a></li>
								
									<li class="nav-item "><a href="/basics/simulation/">Simulation</a></li>
								
									<li class="nav-item "><a href="/basics/descriptive/">Descriptive Statistics</a></li>
								
									<li class="nav-item "><a href="/basics/summary/">Summary Statistics</a></li>
								
									<li class="nav-item "><a href="/basics/leastsq/">Least Square Method</a></li>
								
									<li class="nav-item "><a href="/basics/mle/">Maximising Likelihoods</a></li>
								
							</ul>
						</li>
					
						<li class="nav-item top-level ">
							
							<a href="/bayes-basics/theorem/">Bayesian Basics</a>
							<ul>
								
									<li class="nav-item "><a href="/bayes-basics/theorem/">Bayes' Theorem</a></li>
								
									<li class="nav-item "><a href="/bayes-basics/prior/">Prior Distribution</a></li>
								
									<li class="nav-item "><a href="/bayes-basics/likelihood/">Model Likelihood</a></li>
								
									<li class="nav-item "><a href="/bayes-basics/posterior/">Posterior Distribution</a></li>
								
									<li class="nav-item "><a href="/bayes-basics/diagnosis/">Checking Fitted Models</a></li>
								
							</ul>
						</li>
					
						<li class="nav-item top-level ">
							
							<a href="/cognitive-model/lba/">Cognitive Model</a>
							<ul>
								
									<li class="nav-item "><a href="/cognitive-model/lba/">LBA Model</a></li>
								
									<li class="nav-item "><a href="/cognitive-model/pm/">PM Model</a></li>
								
									<li class="nav-item "><a href="/cognitive-model/plba/">PLBA Model</a></li>
								
									<li class="nav-item "><a href="/cognitive-model/ddm/">Diffusion Decision Model</a></li>
								
									<li class="nav-item "><a href="/cognitive-model/ddm1c/">One-choice Diffusion Decision Model</a></li>
								
									<li class="nav-item "><a href="/cognitive-model/cddm/">Circular Drift-diffusion Model</a></li>
								
									<li class="nav-item "><a href="/cognitive-model/pddm/">PDDM</a></li>
								
									<li class="nav-item "><a href="/cognitive-model/lba3/">Three-accumulator LBA Model</a></li>
								
									<li class="nav-item "><a href="/cognitive-model/lca/">LCA Model</a></li>
								
							</ul>
						</li>
					
						<li class="nav-item top-level ">
							
							<a href="/fixed-effect-model/one_participant/">Fixed-effects Model</a>
							<ul>
								
									<li class="nav-item "><a href="/fixed-effect-model/one_participant/">One Participant</a></li>
								
									<li class="nav-item "><a href="/fixed-effect-model/many_participants/">Multiple Participants</a></li>
								
									<li class="nav-item "><a href="/fixed-effect-model/cddm12S/">CDDM</a></li>
								
							</ul>
						</li>
					
						<li class="nav-item top-level ">
							
							<a href="/mcmc/mcmc/">Modern Bayesian Statistics</a>
							<ul>
								
									<li class="nav-item "><a href="/mcmc/mcmc/">Markov Chain Monte Carlo</a></li>
								
									<li class="nav-item "><a href="/mcmc/rwm/">Random Walk Metropolis</a></li>
								
									<li class="nav-item "><a href="/mcmc/hastings/">Metropolis-Hastings</a></li>
								
							</ul>
						</li>
					
						<li class="nav-item top-level ">
							
							<a href="/random-effect-model/hlba/">Hierarchical Model</a>
							<ul>
								
									<li class="nav-item "><a href="/random-effect-model/hlba/">HLBA Model</a></li>
								
									<li class="nav-item "><a href="/random-effect-model/hddm/">HDDM</a></li>
								
									<li class="nav-item "><a href="/random-effect-model/shooting-decision1/">Shooting Decision Model - Recovery Study</a></li>
								
									<li class="nav-item "><a href="/random-effect-model/shooting-decision2/">Shooting Decision Model - Empirical Data</a></li>
								
									<li class="nav-item "><a href="/random-effect-model/hcddm/">HCDDM</a></li>
								
									<li class="nav-item "><a href="/random-effect-model/hpm/">HPM Model</a></li>
								
							</ul>
						</li>
					
						<li class="nav-item top-level ">
							
							<a href="/sampling/genetic/">Sampling Techniques</a>
							<ul>
								
									<li class="nav-item "><a href="/sampling/genetic/">Population-based Monte Carlo</a></li>
								
									<li class="nav-item "><a href="/sampling/crossover/">Crossover</a></li>
								
									<li class="nav-item "><a href="/sampling/migration/">Migration</a></li>
								
									<li class="nav-item "><a href="/sampling/mutation/">Mutation</a></li>
								
									<li class="nav-item "><a href="/sampling/demc/">Differential Evolution Monte Carlo</a></li>
								
									<li class="nav-item "><a href="/sampling/demcmc/">Differential Evolution Markov Chain Monte Carlo</a></li>
								
									<li class="nav-item "><a href="/sampling/dgmc/">Distributed Genetic Monte Carlo</a></li>
								
							</ul>
						</li>
					
				</ul>

				<ul>
					<li class="nav-item top-level ">
						
						<a href="/changelog/">Change Log</a>
					</li>
				</ul>
			</nav>
		</header>

		<section class="main">
			<div class="page-header">
				<h2>BUGS Examples Volumn 1</h2>
				<h3>Hierarchical Normal Model</h3>
			</div>
			<article class="content">
				<p>Disclaimer: This tutorial uses an experimental (beta) version of <em>ggdmc</em>, which 
has added the functionality of fitting regression models.  The software 
can be found in its GitHub.</p>

<p>The aim of tutorial is to docuemnt one method to fit an hierarchical 
normal model, using the <a href="http://www.openbugs.net/Examples/Rats.html">Rats data</a>.
Rats data were studied in Gelfand (1990) and used in the BUGS examples volumn I.
This expands the scope of ggdmc, not only to fit cognitive models but also to fit
standard regression models.</p>

<p>I first convert the data from wide to long format.</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  setwd("~/BUGS_Examples/vol1/Rats/")
  tmp &lt;- dget("data/dataBUGS.R")
  d &lt;- data.frame(matrix(as.vector(tmp$Y), nrow = 30, byrow = TRUE))
  names(d) &lt;- c(8, 15, 22, 29, 36)
  d$s &lt;- factor(1:tmp$N)
  long &lt;- melt(d, id.vars = c("s"), variable.name = "xfac",
               value.name = "RT")
  dplyr::tbl_df(long)
  long$X &lt;- as.double(as.character(long$xfac)) - tmp$xbar
  long$S &lt;- factor("x1")
  long$R &lt;- factor("r1")
  d &lt;- long[, c("s", "S", "R", "X", "RT")]
</code></pre></div></div>

<p>The data can be visualized as many lines, each representing a subject (rat).</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>p1 &lt;- ggplot(d1, aes(x = X, y = RT, group = s, colour = s)) +
    geom_line(size = 1) + 
    geom_point() + ylab("Weight") +
    ggtitle("Complete data") +
    coord_cartesian(ylim = c(120, 380)) +
    scale_colour_grey(na.value = "black") +
    theme_bw(base_size = 20) +
    theme(legend.position = "none") 
</code></pre></div></div>

<p><img src="/images/BUGS/rats_complete.png" alt="rats" /></p>

<h2 id="set-up-model">Set-up Model</h2>
<p>The DDM composes of two complementary defective distribtions; thereby,
two response types. Unlike the DDM, a regression model has only one response type;
that is one (complete) distribution. Therefore, the <em>match.map</em> and <em>responses</em>
arguments are set as <em>NULL</em> and <em>“r1”</em> (meaning only one response type).</p>

<p>The argument <em>regressors</em> enters the independent / predictive
variable (typically denoted X).  In the Rats example, the weights of thirty
young rats were measured weekly for five weeks and the measurements taken at the
end of each week (8th, 15th, 22rd, 29th, &amp; 36th day) were provided. The
parameterization is <em>a</em> (intercept), <em>b</em> (slope) and the precision (<script type="math/tex">= 1/sd^2</script>).</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">require</span><span class="p">(</span><span class="n">ggdmc</span><span class="p">)</span>
<span class="k">model</span> <span class="p">&lt;-</span> <span class="n">BuildModel</span><span class="p">(</span>
    <span class="n">p</span><span class="p">.</span><span class="n">map</span>      <span class="p">=</span> <span class="k">list</span><span class="p">(</span><span class="n">a</span> <span class="p">=</span> <span class="s2">"1"</span><span class="p">,</span> <span class="n">b</span> <span class="p">=</span> <span class="s2">"1"</span><span class="p">,</span> <span class="n">tau</span> <span class="p">=</span> <span class="s2">"1"</span><span class="p">),</span>
    <span class="n">match</span><span class="p">.</span><span class="n">map</span>  <span class="p">=</span> <span class="n">NULL</span><span class="p">,</span>
    <span class="n">regressors</span> <span class="p">=</span> <span class="n">c</span><span class="p">(</span><span class="m">8</span><span class="p">,</span> <span class="m">15</span><span class="p">,</span> <span class="m">22</span><span class="p">,</span> <span class="m">29</span><span class="p">,</span> <span class="m">36</span><span class="p">)</span> <span class="p">-</span> <span class="n">tmp</span><span class="p">$</span><span class="n">xbar</span><span class="p">,,</span> 
    <span class="n">factors</span>    <span class="p">=</span> <span class="k">list</span><span class="p">(</span><span class="n">S</span> <span class="p">=</span> <span class="n">c</span><span class="p">(</span><span class="s2">"x1"</span><span class="p">)),</span>
    <span class="n">responses</span>  <span class="p">=</span> <span class="s2">"r1"</span><span class="p">,</span>
    <span class="n">constants</span>  <span class="p">=</span> <span class="n">NULL</span><span class="p">,</span>
    <span class="n">type</span>       <span class="p">=</span> <span class="s2">"glm"</span><span class="p">)</span>
<span class="p">##</span> <span class="n">Parameter</span> <span class="n">vector</span> <span class="n">names</span> <span class="n">are</span><span class="p">:</span> <span class="p">(</span> <span class="n">see</span> <span class="n">attr</span><span class="p">(,</span><span class="s2">"p.vector"</span><span class="p">)</span> <span class="p">)</span>
<span class="p">##</span> <span class="p">[</span><span class="m">1</span><span class="p">]</span> <span class="s2">"a"</span>   <span class="s2">"b"</span>   <span class="s2">"tau"</span>
<span class="p">##</span> 
<span class="p">##</span> <span class="n">Constants</span> <span class="n">are</span> <span class="p">(</span><span class="n">see</span> <span class="n">attr</span><span class="p">(,</span><span class="s2">"constants"</span><span class="p">)</span> <span class="p">):</span>
<span class="p">##</span> <span class="n">NULL</span>
<span class="p">##</span> 
<span class="p">##</span> <span class="k">Model</span> <span class="n">type</span> <span class="p">=</span> <span class="n">glm</span>

</code></pre></div></div>

<h2 id="recovery-study">Recovery Study</h2>
<p>I take values from the Rats example as the true parameters at
the population level and use them to simulate an ideal data set, 
which has 1000 rats and each of them contributes 100 response.
<em>tnorm2</em> is truncated normal distribution, using mean and precision
parametrization. When both the upper and lower are set NA, the tnorm
becomes normal distribution.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>npar &lt;- length(GetPNames(model))
pop.location  &lt;- c(a = 242.7, b = 6.189, tau = .03)
pop.scale &lt;- c(a = .005, b = 3.879, tau = .04)
ntrial &lt;- 100
pop.prior  &lt;-BuildPrior(
   dists = rep("tnorm2", npar),
   p1    = pop.location,
   p2    = pop.scale,
   lower = c(NA, 0, 0),
   upper = rep(NA, npar))
dat &lt;- simulate(model, nsub = 1000, nsim = ntrial, prior = pop.prior)
dmi &lt;- BuildDMI(dat, model)
ps  &lt;- attr(dat, "parameters") ## Extract true parameters for each individual
</code></pre></div></div>

<p>This plots the distributions that generate the simulation data and shows the
location parameters of these distributions as dashed lines.</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>plot(pop.prior, ps = pop.mean)
</code></pre></div></div>

<p><img src="/images/BUGS/pop_prior.png" alt="pop_prior" /></p>

<h3 id="set-up-priors">Set up Priors</h3>
<p>To randomly draw initial values for the data- and hyper-level parameters,
I set up three sets of distributions and bind them as a list, named <em>start</em>.
These are used to generate start values only.</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pstart &lt;- BuildPrior(
    dists = c("tnorm", "tnorm", "tnorm"),
    p1    = c(a = 242,  b = 6.19, tau = .027),
    p2    = c(a = 14, b = .49, tau = 10),
    lower = c(NA, NA, 0),
    upper = rep(NA, npar))
lstart &lt;- BuildPrior(
    dists = c("tnorm", "tnorm", "tnorm"),
    p1    = c(a = 200,  b = 5, tau = .01),
    p2    = c(a = 50, b = 1, tau = .01),
    lower = c(NA, NA, 0),
    upper = rep(NA, npar))
sstart &lt;- BuildPrior(
    dists = c("tnorm", "tnorm", "tnorm"),
    p1    = c(a = 10,  b = .5, tau = .01),
    p2    = c(a = 5, b = .1, tau = .01),
    lower = c(NA, NA, 0),
    upper = rep(NA, npar))
start &lt;- list(pstart, lstart, sstart)
</code></pre></div></div>

<p>Next, I set up the structure of the hierarchical model.  It is 
important to understand the hierarchical structure, so I sketch a diagram to 
show how the codes of setting up the prior distributions associate with
the model structure.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>p.prior  &lt;- BuildPrior(
    dists = rep("tnorm2", npar),
    p1    = c(a = NA, b = NA, tau = NA),  ## the value are drawn from hyper-level
    p2    = rep(NA, 3),                   ## (mu and sigma) prior, so all set NA
    lower = c(NA, 0, 0),
    upper = rep(NA, npar))
mu.prior  &lt;- BuildPrior(
    dists = rep("tnorm2", npar),
    p1    = c(a = 200, b = 6, tau = 3)
	p2    = c(a = 1e-4, b = 1e-3, tau = 1e-2)
    lower = c(NA, 0, 0),
    upper = rep(NA, npar))
sigma.prior &lt;- BuildPrior(
    dists = rep("gamma", npar),
    p1    = c(a = .01, b = .01, tau = .01),
    p2    = c(a = 1000,  b = 1000, tau = 1000),
    lower = c(0, 0, 0),
    upper = rep(NA, npar))
prior &lt;- list(p.prior, mu.prior, sigma.prior)

</code></pre></div></div>
<p><img src="/images/BUGS/model.png" alt="model structure" /></p>

<h2 id="sampling">Sampling</h2>
<p>The function, <em>StartNewhiersamples</em> use the <em>start</em> priors
only for drawing initial values. The <em>prior</em> distributions wil
be used in the model fit.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>fit &lt;- run(StartNewhiersamples(5e2, dmi, start, prior))
fit &lt;- run(RestartHypersamples(5e2, fit, thin = 32))
</code></pre></div></div>

<h2 id="model-diagnosis">Model Diagnosis</h2>
<p>As usually, I check the potential scale reduction factors (Brook &amp; Gelman,1998),
effective sample sizes, and trace plots.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>rhat &lt;- hgelman(fit, verbose = TRUE)
hes &lt;- effectiveSize(hsam, hyper = TRUE)
es1 &lt;- effectiveSize(hsam[[1]])

##    a.h1     b.h1   tau.h1     a.h2     b.h2   tau.h2 
## 427.9587 767.7925 483.1228 613.3212 730.1198 462.4242 
##        a        b      tau 
## 569.3685 609.0303 572.1573 

p0 &lt;- plot(fit, hyper = TRUE)
p1 &lt;- plot(fit, hyper = TRUE, pll = FALSE, den = TRUE)
  
</code></pre></div></div>
<p><img src="/images/BUGS/traceplot1.png" alt="traceplot" />
<img src="/images/BUGS/densityplot1.png" alt="density-hyper" /></p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>est1 &lt;- summary(fit, hyper = TRUE, recover = TRUE, start = 101,
                ps = pop.mean,  type = 1, verbose = TRUE, digits = 3)
est2 &lt;- summary(fit, hyper = TRUE, recover = TRUE, start = 101,
                ps = pop.scale, type = 2, verbose = TRUE, digits = 3)
est3 &lt;- summary(fit, recover = TRUE, ps = ps, verbose = TRUE)
				  
##                     a      b    tau
## True           242.700  6.189 0.030
## 2.5% Estimate  241.456  6.143 0.008
## 50% Estimate   242.275  6.173 0.460
## 97.5% Estimate 243.081  6.206 1.338
## Median-True     -0.425 -0.016 0.430
## 
##                    a      b   tau
## True           0.005  3.879 0.040
## 2.5% Estimate  0.005  3.533 0.042
## 50% Estimate   0.005  3.835 0.047
## 97.5% Estimate 0.005  4.156 0.058
## Median-True    0.000 -0.044 0.007
## 
## Summary each participant separately
##           a    b   tau
## Mean 242.28 6.17  3.82
## True 242.29 6.17  3.81
## Diff   0.01 0.00 -0.01
## Sd    14.14 0.51  2.80
## True  14.13 0.51  2.91
## Diff   0.00 0.00  0.11

</code></pre></div></div>

<h2 id="model-fit-to-rats-data">Model Fit to Rats Data</h2>
<p>After verifying that the model structure is OK, I then fit the
<a href="http://www.openbugs.net/Examples/Rats.html">Rats data</a>.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## Each rat contribute 5 trials / observations
DT &lt;- data.table(d)
DT[, .N, .(s)]
##      s N
##  1:  1 5
##  2:  2 5
##  3:  3 5
##  ...
## 30: 30 5
</code></pre></div></div>

<p>Now, I bind the Rats data with the model and start sampling.
The estimates are fairly similar with BUGS and Stan estimations.
The only significant difference is the tau.h1, which simply
due the more complex structure used here.</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
dmi &lt;- BuildDMI(d, model)
fit0 &lt;- run(StartNewhiersamples(500, dmi, start, prior))
fit  &lt;- run(RestartHypersamples(5e2, fit0, thin = 32))

est1 &lt;- summary(fit, hyper = TRUE, type = 1, verbose = TRUE)
round( est1$quantiles, 3)
#              2.5%   25%     50%      75%  97.5%
# a.h1      237.37 240.69  242.49  244.12  247.75
# mu_alpha  237.09 240.68  242.47  244.29  247.84  ## Stan
# alpha.c   237.10 240.90  242.70  244.50  248.10  ## BUGS
# b.h1        5.98   6.10    6.17    6.24    6.37
# mu_beta     5.97   6.11    6.18    6.26    6.40  ## Stan
# beta.c      5.97   6.12    6.19    6.26    6.40  ## BUGS
  
# tau.h1     0.012  0.035   0.042   0.047   0.056
# Stan       0.020  0.024   0.027   0.030   0.036  
# BUGS       0.020  0.024   0.027   0.030   0.036
  
# a.h2       0.003   0.004   0.005   0.006   0.008
# alpha.tau  0.003   0.004   0.005   0.006   0.008 ## BUGS
# b.h2       2.049   3.111   3.838   4.683   6.714
# beta.tau   1.952   3.078   3.879   4.922   8.026 ## BUGS

hes &lt;- effectiveSize(fit, hyper = TRUE)
##     a.h1     b.h1   tau.h1     a.h2     b.h2   tau.h2 
## 4500.000 4534.287 4193.927 3807.489 4079.768 3139.033
   
round(apply(data.frame(es), 1, mean))
round(apply(data.frame(es), 1, sd))
round(apply(data.frame(es), 1, max))
round(apply(data.frame(es), 1, min))
##         a    b  tau 
## Mean 4464 4360 4321 
## SD    139  242  348 
## MAX  4717 5020 5137 
## MIN  4100 3732 3455 
  
</code></pre></div></div>

<p><img src="/images/BUGS/traceplot_rats.png" alt="traceplot_rat" />
<img src="/images/BUGS/densityplot_rats.png" alt="density_rat" /></p>

<h2 id="handling-missing-data">Handling Missing Data</h2>
<p>Rats example also considered fitting missing data. This can be done by
setting the missing data as NA or downloading the missing data set
directly from <a href="http://www.openbugs.net/Examples/Rats.html">BUGS site</a>.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>d[6:10,5] &lt;- NA
d[11:20,4:5] &lt;- NA
d[21:25,3:5] &lt;- NA
d[26:30,2:5] &lt;- NA
</code></pre></div></div>

<p>and bind the data with the same model set up previously.
Again, the results are fairly similar with using other Bayesian software.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>dmi &lt;- BuildDMI(d[!is.na(d$RT),], model)

  #            2.5%     25%    50%    75%     97.5%
  # a.h1     241.01  244.35  246.07  247.73  251.09
  # alpha.c  240.30  243.90  245.80  247.70  251.30 BUGS
  # b.h1      6.362   6.526   6.605   6.688   6.844
  # beta.c    6.286   6.477   6.572   6.669   6.870 BUGS
  # a.h2      0.003   0.004   0.005   0.006   0.009
  # alpha.tau 0.003   0.004   0.005   0.006   0.009 BUGS
  # b.h2      1.640   2.757   3.595   4.479   7.241
  # beta.tau  1.505   2.676   3.620   5.044  13.601 BUGS


</code></pre></div></div>

<p>The predictions for the final four observations on rat 26 can be
obtained by entering predict_one function with fit[[26]].</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pp26 &lt;- predict_one(fit[[26]])
pred26 &lt;- pp26[, .(Mean = mean(RT)), .(X)]
pred26[c(2,1,3,4,5),]

##      X     Mean
## 1: -14 160.8060  
## 2:  -7 203.8068  Y[26, 2] = 204.6
## 3:   0 249.4786  Y[26, 3] = 250.2
## 4:   7 297.8309  Y[26, 4] = 295.6
## 5:  14 339.6564  Y[26, 5] = 341.2

</code></pre></div></div>

<h2 id="reference">Reference</h2>
<p>Gelfand, A. E., Hills, S. E., Racine-Poon, A., &amp; Smith, A. F. (1990). Illustration
of Bayesian inference in normal data models using Gibbs sampling. <em>Journal of
the American Statistical Association</em>, 85(412), 972-985.</p>


			</article>
		</section>

		<script>
			document.getElementById("open-nav").addEventListener("click", function () {
				document.body.classList.toggle("nav-open");
			});

			
		</script>

		  
		</script>
	</body>
</html>
