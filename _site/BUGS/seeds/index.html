<!DOCTYPE html>

<html>
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1">

		<!-- Begin Jekyll SEO tag v2.4.0 -->
<title>Random effect logistic regression | Cognitive Models</title>
<meta name="generator" content="Jekyll v3.7.2" />
<meta property="og:title" content="Random effect logistic regression" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Disclaimer: This tutorial uses an experimental (beta) version of ggdmc, which has added the functionality of fitting logistic regression models. The software can be found in its GitHub. This document has yet completed." />
<meta property="og:description" content="Disclaimer: This tutorial uses an experimental (beta) version of ggdmc, which has added the functionality of fitting logistic regression models. The software can be found in its GitHub. This document has yet completed." />
<link rel="canonical" href="http://localhost:4000/BUGS/seeds/" />
<meta property="og:url" content="http://localhost:4000/BUGS/seeds/" />
<meta property="og:site_name" content="Cognitive Models" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2018-12-16T13:43:21+00:00" />
<script type="application/ld+json">
{"@type":"Article","publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"http://localhost:4000/siteicon.png"}},"url":"http://localhost:4000/BUGS/seeds/","headline":"Random effect logistic regression","dateModified":"2018-12-16T13:43:21+00:00","datePublished":"2018-12-16T13:43:21+00:00","description":"Disclaimer: This tutorial uses an experimental (beta) version of ggdmc, which has added the functionality of fitting logistic regression models. The software can be found in its GitHub. This document has yet completed.","@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->

		<link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="Cognitive Models" />

		<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Merriweather:400,400italic,700,700italic|Open+Sans:400,400italic,600,600italic,700,700italic|Inconsolata:400,700">
		<link rel="stylesheet" href="/css/main.css">
		<link rel="apple-touch-icon" href="/apple-touch-icon.png">
		<link rel="icon" type="image/png" href="/touch-icon.png" sizes="192x192">
		<link rel="icon" type="image/png" href="/images/favicon.png">

		
	</head>

	<body>
	  <header>
	    <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML"></script>
	    
			<h1>
				<a href="/"><img src="/images/emblem.svg" width="40" height="40" alt="Cognitive Models logo"></a>
				Cognitive Models
				<button type="button" class="open-nav" id="open-nav"></button>
			</h1>

			<form action="/search/" method="get">
				<input type="text" name="q" id="search-input" placeholder="Search" autofocus>
				<input type="submit" value="Search" style="display: none;">
			</form>

			<nav >
				<ul>
					<li class="nav-item top-level ">
						
						<a href="/"></a>
					</li>
				</ul>

				<ul>
					
					
						<li class="nav-item top-level current">
							
							<a href="/BUGS/hnormal/">BUGS Examples Volumn 1</a>
							<ul>
								
									<li class="nav-item "><a href="/BUGS/hnormal/">Hierarchical Normal Model</a></li>
								
									<li class="nav-item current"><a href="/BUGS/seeds/">Random effect logistic regression</a></li>
								
							</ul>
						</li>
					
						<li class="nav-item top-level ">
							
							<a href="/approximation/kde/">Likelihood Free Method</a>
							<ul>
								
									<li class="nav-item "><a href="/approximation/kde/">Kernel Density Estimation</a></li>
								
									<li class="nav-item "><a href="/approximation/pda/">Probability Density Approximation</a></li>
								
									<li class="nav-item "><a href="/approximation/ppda/">Parallel Probability Density Approximation</a></li>
								
							</ul>
						</li>
					
						<li class="nav-item top-level ">
							
							<a href="/basics/model_array/">Modelling Basics</a>
							<ul>
								
									<li class="nav-item "><a href="/basics/model_array/">Model Array</a></li>
								
									<li class="nav-item "><a href="/basics/simulation/">Simulation</a></li>
								
									<li class="nav-item "><a href="/basics/descriptive/">Descriptive Statistics</a></li>
								
									<li class="nav-item "><a href="/basics/summary/">Summary Statistics</a></li>
								
							</ul>
						</li>
					
						<li class="nav-item top-level ">
							
							<a href="/bayes-basics/theorem/">Bayesian Basics</a>
							<ul>
								
									<li class="nav-item "><a href="/bayes-basics/theorem/">Bayes' Theorem</a></li>
								
									<li class="nav-item "><a href="/bayes-basics/prior/">Prior Distribution</a></li>
								
									<li class="nav-item "><a href="/bayes-basics/likelihood/">Model Likelihood</a></li>
								
									<li class="nav-item "><a href="/bayes-basics/posterior/">Posterior Distribution</a></li>
								
							</ul>
						</li>
					
						<li class="nav-item top-level ">
							
							<a href="/cognitive-model/sdt/">Cognitive Model</a>
							<ul>
								
									<li class="nav-item "><a href="/cognitive-model/sdt/">Signal Detection Model</a></li>
								
									<li class="nav-item "><a href="/cognitive-model/lba/">Linear Ballistic Accumulation Model</a></li>
								
									<li class="nav-item "><a href="/cognitive-model/ddm/">Diffusion Decision Model</a></li>
								
									<li class="nav-item "><a href="/cognitive-model/cddm/">Circular Diffusion Decision Model</a></li>
								
									<li class="nav-item "><a href="/cognitive-model/plba/">PLBA Model</a></li>
								
									<li class="nav-item "><a href="/cognitive-model/pddm/">PDDM</a></li>
								
									<li class="nav-item "><a href="/cognitive-model/lba3/">Three-accumulator LBA Model</a></li>
								
							</ul>
						</li>
					
						<li class="nav-item top-level ">
							
							<a href="/fixed-effect-model/one_participant/">Fixed Effects Model</a>
							<ul>
								
									<li class="nav-item "><a href="/fixed-effect-model/one_participant/">One Participant</a></li>
								
									<li class="nav-item "><a href="/fixed-effect-model/many_participants/">Multiple Participants</a></li>
								
							</ul>
						</li>
					
						<li class="nav-item top-level ">
							
							<a href="/mcmc/mcmc/">Modern Bayesian Statistics</a>
							<ul>
								
									<li class="nav-item "><a href="/mcmc/mcmc/">Markov Chain Monte Carlo</a></li>
								
									<li class="nav-item "><a href="/mcmc/rwm/">Random Walk Metropolis</a></li>
								
									<li class="nav-item "><a href="/mcmc/hastings/">Metropolis-Hastings</a></li>
								
							</ul>
						</li>
					
						<li class="nav-item top-level ">
							
							<a href="/random-effect-model/hlba/">Hierarchical Model</a>
							<ul>
								
									<li class="nav-item "><a href="/random-effect-model/hlba/">Hierarchical LBA Model</a></li>
								
									<li class="nav-item "><a href="/random-effect-model/hddm/">Hierarchical DDM</a></li>
								
									<li class="nav-item "><a href="/random-effect-model/hcddm/">Hierarchical Circular DDM</a></li>
								
									<li class="nav-item "><a href="/random-effect-model/shooting-decision1/">Shooting Decision Model - Recovery Study</a></li>
								
									<li class="nav-item "><a href="/random-effect-model/shooting-decision2/">Shooting Decision Model - Empirical Data</a></li>
								
							</ul>
						</li>
					
						<li class="nav-item top-level ">
							
							<a href="/sampling/genetic/">Sampling Techniques</a>
							<ul>
								
									<li class="nav-item "><a href="/sampling/genetic/">Population-based Monte Carlo</a></li>
								
									<li class="nav-item "><a href="/sampling/crossover/">Crossover</a></li>
								
									<li class="nav-item "><a href="/sampling/migration/">Migration</a></li>
								
									<li class="nav-item "><a href="/sampling/mutation/">Mutation</a></li>
								
									<li class="nav-item "><a href="/sampling/demc/">Differential Evolution Monte Carlo</a></li>
								
									<li class="nav-item "><a href="/sampling/demcmc/">Differential Evolution Markov Chain Monte Carlo</a></li>
								
									<li class="nav-item "><a href="/sampling/dgmc/">Distributed Genetic Monte Carlo</a></li>
								
							</ul>
						</li>
					
				</ul>

				<ul>
					<li class="nav-item top-level ">
						
						<a href="/changelog/">Change Log</a>
					</li>
				</ul>
			</nav>
		</header>

		<section class="main">
			<div class="page-header">
				<h2>BUGS Examples Volumn 1</h2>
				<h3>Random effect logistic regression</h3>
			</div>
			<article class="content">
				<p>Disclaimer: This tutorial uses an experimental (beta) version of <em>ggdmc</em>, which 
has added the functionality of fitting logistic regression models.  The software 
can be found in its GitHub. This document has yet completed.</p>

<p>The aim of tutorial is to document one method to fit the logistic regression 
model, using the <a href="http://www.openbugs.net/Examples/Seeds.html">Seeds data</a>.
Seeds data were studied in Crowder (1978), re-analysed by Breslow and Clayton (1993)
and used in the BUGS examples volumn I. This document expands the scope of ggdmc
to the logistic regression model.</p>

<p>An ordinary logistic model can fit either binary (response) data (i.e., 0, 1, 0, …)
or binomial data (i.e., proportional data, as the Seeds example).  The simplest form of
the random-effect (multilevel) logistic model is to presume observation units are
drawn from a normal distribution.</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align*}
& y_i \sim Binomial(p_i, n_i) \\
& p_i = logit^{-1}(\mathbf{X} \beta + s_i) \\
& s_i \sim N(0, \sigma^2)
\end{align*} %]]></script>

<p>This two-level model can be compared to the model presuming observation units are
as they been observed (i.e., fixed-effect logistic regression model).</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align*}
& y_i \sim Binomial(p_i, n_i) \\
& p_i = logit^{-1}(\mathbf{X} \beta) \\
\end{align*} %]]></script>

<p>Here I use the formulation of anti-logit, because firstly it is easier to interpret the
probability of success (i.e., <script type="math/tex">p_i</script>) and secondly it is practically how
computer codes been implemented. The idea of transforming binary or binomial responses
with logit is still conceptually important for the generalized linear model though.</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align*}
& logit(p_i) =\mathbf{X} \beta \\
\end{align*} %]]></script>

<p>Because the Seeds data set was formatted as <em>List</em>, I convert the data to data frame
format.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>rm(list = ls())
library(data.table); library(boot)
## Load Seeds data ------------
## 2 x 2 design
setwd("~/BUGS_Examples/vol1/Seeds/")
dat &lt;- list(S = c(10, 23, 23, 26, 17,  5, 53, 55, 32, 46,
                  10,  8, 10,  8, 23,  0,  3, 22, 15, 32,
                  3),
            N = c(39, 62, 81, 51, 39,  6, 74, 72, 51, 79,
                  13, 16, 30, 28, 45,  4, 12, 41, 30, 51,
                  7),
            ## seed variety; 0 = aegytpiao 75 1 = aegyptiao 73
            X1 = c(0, 0, 0, 0, 0,  0, 0, 0, 0, 0,
                   0, 1, 1, 1, 1,  1, 1, 1, 1, 1,
                   1),
            ## root extract; 0 = bean; 1 = cucumber
            X2 = c(0, 0, 0, 0, 0,  1, 1, 1, 1, 1,
                   1, 0, 0, 0, 0,  0, 1, 1, 1, 1,
                   1),
            Ns = 21)

d &lt;- data.table(S = dat$S, N = dat$N, P = dat$S/dat$N, X1= dat$X1, X2 = dat$X2)
dplyr::tbl_df(d)
d$s &lt;- factor(1:dat$Ns)
## A tibble: 21 x 7
##        S     N     P    X1    X2   logit s
##    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt; &lt;fct&gt;
##  1    10    39 0.256     0     0 -1.06   1
##  2    23    62 0.371     0     0 -0.528  2
##  3    23    81 0.284     0     0 -0.925  3
##  4    26    51 0.510     0     0  0.0392 4 
##  5    17    39 0.436     0     0 -0.258  5
##  6     5     6 0.833     0     1  1.61   6 
##  7    53    74 0.716     0     1  0.926  7
##  8    55    72 0.764     0     1  1.17   8
##  9    32    51 0.627     0     1  0.521  9 
## 10    46    79 0.582     0     1  0.332  10
## ... with 11 more rows
</code></pre></div></div>
<ul>
  <li><em>S</em>, the number of (successfully) germinated seeds on the ith plate (i = 1, … N);</li>
  <li><em>N</em>, the number of total seeds on the ith plate;</li>
  <li><em>P</em>, the proportion of germinated seeds;</li>
  <li><em>X1</em>, a two-level seed factor, aegyptiao 75 vs. aegyptiao 73;</li>
  <li><em>X2</em>, a two-level root extract factor, bean vs. cucumber;</li>
  <li><em>logit</em>, as the column name says;</li>
  <li><em>s</em>, subject, namely, the observation unit.</li>
</ul>

<p><img src="/images/BUGS/seeds/data.png" alt="seeds" /></p>

<p>The interaction plot shows that the root extract type, cucumber, has a drastic
increase in successful germination when the seed type is aegyptiao 75, comparing to
when the seed type is aegyptaio 73 and this change is small and in an opposite
direction in the root extract type, bean.</p>

<p>The data can be analysed with the ordinary logistic regression (OLR) model or
multilevel logistic regression model. The OLR replicates the result in
Table 3 (1st column) in Breslow and Clayton (1993). I use
the <em>display</em> function in the arm package, which shows summary result concisely
(AIC is calculated separately).</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>m1 &lt;- glm(cbind(S, N-S) ~ X1 + X2, family = binomial, data = d)
arm::display(m1)
## Breslow's result in Table 3 p15
## glm(formula = cbind(S, N - S) ~ X1 + X2, family = binomial, data = d)
##             coef.est coef.se
## (Intercept) -0.43     0.11
## X1          -0.27     0.15
## X2           1.06     0.14
## ---
## n = 21, k = 3
## residual deviance = 39.7, null deviance = 98.7 (difference = 59.0)
## AIC: 122.28


m2 &lt;- glm(cbind(S, N-S) ~ X1*X2, family = binomial, data = d)
arm::display(m2)
## glm(formula = cbind(S, N - S) ~ X1 * X2, family = binomial, data = d)
##             coef.est coef.se
## (Intercept) -0.56     0.13
## X1           0.15     0.22
## X2           1.32     0.18
## X1:X2       -0.78     0.31
## ---
## n = 21, k = 4
## residual deviance = 33.3, null deviance = 98.7 (difference = 65.4)
## AIC: 117.87

require(lme4)
m3 &lt;- glmer(cbind(S, N - S) ~ X1 * X2 + (1 | s), family = binomial(link="logit"), data = d)
arm::display(m3)
## glmer(formula = cbind(S, N - S) ~ X1 * X2 + (1 | s), data = d, 
##       family = binomial(link = "logit"))
##          coef.est coef.se
## (Intercept) -0.55     0.17
## X1           0.10     0.28
## X2           1.34     0.24
## X1:X2       -0.81     0.38
## 
## Error terms:
## Groups   Name        Std.Dev.
## s        (Intercept) 0.23
## Residual             1.00
## ---
## number of obs: 21, groups: s, 21
## AIC = 117.5, DIC = -74.6
## deviance = 16.5 
			
</code></pre></div></div>

<table>
  <thead>
    <tr>
      <th> </th>
      <th>glm</th>
      <th> </th>
      <th>glmer</th>
      <th> </th>
      <th>BUGS</th>
      <th> </th>
      <th>ggdmc</th>
      <th> </th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td> </td>
      <td><script type="math/tex">\beta</script></td>
      <td>se</td>
      <td><script type="math/tex">\beta</script></td>
      <td>se</td>
      <td><script type="math/tex">\beta</script></td>
      <td>se</td>
      <td><script type="math/tex">\beta</script></td>
      <td>se</td>
    </tr>
    <tr>
      <td><script type="math/tex">\alpha_0</script></td>
      <td>-0.558</td>
      <td>0.126</td>
      <td>-0.548</td>
      <td>0.166</td>
      <td>-0.557</td>
      <td>0.197</td>
      <td> </td>
      <td> </td>
    </tr>
    <tr>
      <td><script type="math/tex">\alpha_{1}</script></td>
      <td>0.146</td>
      <td>0.223</td>
      <td>0.097</td>
      <td>0.277</td>
      <td>0.086</td>
      <td>0.317</td>
      <td> </td>
      <td> </td>
    </tr>
    <tr>
      <td><script type="math/tex">\alpha_{2}</script></td>
      <td>1.318</td>
      <td>0.177</td>
      <td>1.337</td>
      <td>0.236</td>
      <td>1.348</td>
      <td>0.276</td>
      <td> </td>
      <td> </td>
    </tr>
    <tr>
      <td><script type="math/tex">\alpha_{12}</script></td>
      <td>-0.778</td>
      <td>0.306</td>
      <td>-0.810</td>
      <td>0.384</td>
      <td>-0.824</td>
      <td>0.445</td>
      <td> </td>
      <td> </td>
    </tr>
    <tr>
      <td><script type="math/tex">\sigma</script></td>
      <td>—</td>
      <td>—</td>
      <td>0.235</td>
      <td>—</td>
      <td>0.286</td>
      <td>0.146</td>
      <td> </td>
      <td> </td>
    </tr>
  </tbody>
</table>

<h2 id="reference">Reference</h2>
<ul>
  <li><a href="http://www.jstor.org/stable/2290687">Breslow, N. E., &amp; Clayton, D. G. (1993). Approximate inference in generalized linear mixed models. <em>Journal of the American statistical Association</em>, 88(421), 9-25</a>.</li>
  <li><a href="http://www.jstor.org/stable/2346223">Crowder, M. J. (1978). Beta-binomial anova for proportions. Applied statistics, 34-37</a>.</li>
</ul>


			</article>
		</section>

		<script>
			document.getElementById("open-nav").addEventListener("click", function () {
				document.body.classList.toggle("nav-open");
			});

			
		</script>

		  
		</script>
	</body>
</html>
